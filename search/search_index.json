{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#cypose-specialist-models-for-cyanobacteria-live-cell-movies","title":"CyPose - Specialist Models for Cyanobacteria Live Cell Movies","text":"<p>CyPose is a set of specialist segmentation and classification models for photosynthetic bacteria (cyanobacteria), as well as a set of utilities to make training CellPose easier for users who have live cell movies as opposed to single frame data. Code for CyPose can be found at https://github.com/cameronlab/cypose.</p> <p>Note</p> <p>If you're looking to get started quickly, check out the installation instructions.</p> <p>Key documentation:</p> <ul> <li>Installation - Instructions on installing CyPose and its dependencies on your machine.</li> <li>Segmentation - Considerations for using generalist and specialist segmentation models.</li> <li>Classification - Considerations for classification models as well as instructions on training your own model.</li> </ul> <p> The CyPose Team: Zachary Maas \u2022     Clair Huffine \u2022     Anton Avramov \u2022     Chris Brininger \u2022     Jian Wei Tay \u2022     Jeffrey Cameron </p>"},{"location":"classification/","title":"Classification","text":"<p>The segmentation model provided in CyPose has been hand-developed to work well with a variety of cyanobacterial cells, but requires more work to train a model on your data. You will need data containing your respective strains / cell types of interest as follows:</p> <ul> <li>An original movie in nd2 format to pull data from</li> <li>For each cell type, a tif format mask file containing masks specific to each cell type.</li> </ul> <p>Files should be labeled as follows:</p> <ul> <li>A base name for all files from a given movie, used for the nd2. For example, <code>my_movie.nd2</code></li> <li>Files with matching cell type labels added to the masks for that nd2. For example, <code>my_movie_cell1.tif</code></li> </ul> <p>So, for example, you might have the following:</p> <ul> <li><code>my_movie.nd2</code>, <code>my_movie_cell1.tif</code>, <code>my_movie_cell2.tif</code>, <code>my_movie_cell3.tif</code></li> <li><code>my_movie2.nd2</code>, <code>my_movie2_cell1.tif</code>, <code>my_movie2_cell2.tif</code>, <code>my_movie2_cell3.tif</code></li> <li><code>my_movie3.nd2</code>, <code>my_movie3_cell1.tif</code>, <code>my_movie3_cell2.tif</code>, <code>my_movie3_cell3.tif</code></li> </ul> <p>Warning</p> <p>You must have the same set of channels in the same order in each movie used for training.</p> <p>Once you have your data in this format, you can train a custom classifier model using the <code>train_classification_model.py</code> script, after making the following changes:</p> <ul> <li>Update the <code>root_dir</code> variable in the FastND2DataSet loader to point to the directory containing your data.</li> <li>In the ConvNetClassifier class, update the <code>num_channels</code> variable to match the number of channels in your movie and the <code>num_classes</code> variable to match the number of cell types you are training on.</li> </ul> <p>Once that's done, you can run the script to train a model on your data. The script will save the model to a file, which you can then use to classify new data. To do this, you can use the run_classification.py script, which will classify all the cells in a given movie and save the results to a CSV file. This script can be run as follows:</p> <pre><code>python run_classification.py --model_path /path/to/model --data_dir /path/to/data\n</code></pre> <p>This will save the results to a file called <code>classification_results.csv</code> in the data directory. The results will contain the following columns: <pre><code>frame,centroid_x,centroid_y,cell_type\n</code></pre></p> <p>This can then be used in any downstream analysis you wish to perform.</p>"},{"location":"installation/","title":"Installing and Running CyPose","text":"<p>To install CyPose, first clone the repository from GitHub: <pre><code>git clone https://github.com/cameronlab/cypose.git\n</code></pre> You will need to set up a virtual environment, using either virtualenv or conda (or another tool of your choosing). Then, install poetry and the project dependencies: <pre><code>python3 -m pip poetry\npoetry install\n</code></pre></p> <p>This project is structured so that segmentation is easy if you have an input movie in TIF format. See the <code>test_segmentation.sh</code> file for an example of how to run segmentation using a provided model: <pre><code>python run_segmentation.py \\\n                   --input_file \"/path/to/tif\" \\\n                   --output_file \"/path/to/out_masks.tif\" \\\n                   --model ./models/your_model --start_frame 0 --end_frame 224\n</code></pre> By default, this script will segment the input file and output a TIF formatted mask file suitable for use as input for downstream tools like CyAn.</p> <p>Models are provided in one of two formats:</p> <ul> <li>Single channel movies, which are designed to be used against a brightfield image. These are the most versatile.</li> <li>Two channel movies, which are designed for movies with brightfield and chlorphyll images. In the case of some strains, we see better performance using the chlorphyll channel by allowing the model to more reliably learn the morphological differences between distinct celltypes.</li> </ul> <p>By default, our best models are listed by the strain name. You can also choose to use a pre-built cellpose model (e.g. 'cyto2' or 'cyto3') if applying these tools to a celltype that a well performing fine-tuned model is not available for.</p>"},{"location":"models/","title":"Models","text":"<p>CyPose supports a variety of models, including external CellPose and Omnipose models, as well as our fine-tuned models. By default, these models are included in the <code>models</code> directory at the root of this repository.</p> <p>We provide the following custom models:</p> <ul> <li>cypose-7002 - Model for segmentation of PCC 7002.</li> <li>cypose-7002-scratch - Model for segmentation of PCC 7002, trained from scratch.</li> <li>cypose-33047 - Model to segment Anabaena 33047.</li> </ul> <p>`</p>"},{"location":"segmentation/","title":"Segmentation","text":"<p>The segementation algorithms provided by CyPose are derivative of those originally implemented in CellPose. Over the course of trying to leverage CellPose (and its derivative OmniPose), we found that the provided models as well as the code itself were not well-suited to our use case. Consequently, we have fine-tuned specialized models for Cyanobacterial cells and provide extensive documentation on pitfalls that one might encounter when using these models or the CellPose base models and library.</p> <p>Warning</p> <p>The implementation of CellPose provided in their GUI will consistently produce different results than the implementation provided in the underlying Python library, and the differences between the two are not well documented. If your segmentation results are worse than expected, check to see if the GUI implementation produces better results. The GUI and underlying library are likely to diverge as CellPose development continues.</p> <p>Segmentation is performed using the <code>run_segmentation</code> module, found in <code>run_segmetation.py</code>. Input can be in the form of either an ND2 image/movie or a TIF image/movie, and output will be a TIF image/movie containing the segmented masks. The <code>run_segmentation</code> module is designed to be run from the command line, and can be run as follows: <pre><code>python run_segmentation.py \\\n             --input_file \"movie_name\" \\\n             --output_file \"mask_name\" \\\n             --gpu \\\n             --model ./models/model_name \\\n             --start_frame 200 \\\n             --end_frame 205\n</code></pre></p> <p>The following arguments are available:</p> <ul> <li><code>--input_file \"movie_name\"</code>: Specifies the input movie file. ND2 or TIF formatted.</li> <li><code>--output_file \"mask_name\"</code>: Specifies the output mask file. TIF formatted.</li> <li><code>--gpu</code>: Indicates that the script should use the GPU. Device is automatically inferred (MPS for M1 OSX and CUDA for Nvidia GPUs).</li> <li><code>--model ./models/model_name</code>: Specifies the path to the model file. Can also be any built-in Cellpose 2 or 3 model name.</li> <li><code>--start_frame 200</code>: Specifies the start frame for the segmentation.</li> <li><code>--end_frame 205</code>: Specifies the end frame for the segmentation.</li> </ul> <p>Additionally, three experimental options are provided:</p> <ul> <li>--debug: Specifies a debugging run, which will also save probabilities and flows for the model.</li> <li>--denoise: Preliminary experimental support for Cellpose 3's built-in denoising model. We do not currently reccommend using this - if you are going to be doing downstream analysis on your data, don't use low quality data.</li> <li>--niter: Run the model for n-iterations for each frame to generate higher quality frames. This method is derived from Omnipose and can sometimes return better results with high iterations (2000) on bacterial imagery.</li> <li>-flow_threshold: Run the model with a different flow threshold for classifying cells. We use a default of 0.75, compared to the Cellpose default of 0.4, and find generally better results with this approach.</li> </ul> <p>The model output consists of a generated TIF file saved at the user specified location. The output file contains masks for each identified cell separated by integer level. For example, background is indicated by a 0 value, the first cell identified is identified with a 1 value in all pixels containing that cell, and so on for each identified cell. The base Cellpose framework structures output in this way to handle the condition where two segmented cells share a pixel on an edge, as if a single value was used for segmented cells, downstream analysis would treat those cells as merged into a single cell.</p> <p>If generated, the flow-threshold and probability output files contain data in a generic float representation or bounded float (between 0 and 1), respectively. These files are useful for manual verification of model behavior.</p>"}]}